"# ai_embedded_assistant" 

Prerequisition:

- Python 3.9 or later installed.
- Installed dependencies: pip install pdfplumber nltk sentence-transformers chromadb streamlit spacy requests
- Downloaded NLTK data: import nltk; nltk.download('punkt')
- Installed spaCyâ€™s small English model: python -m spacy download en_core_web_sm
- Installed and started Ollama with Mistral-7B loaded: ollama serve & and ollama run mistral
- Created a project folder with a documents/ subfolder containing your PDF files.

=================================================================

Steps to Set Up

1. Create the documents/ folder in your project directory and add your PDF files.

2. Run preprocess.py to process the documents and generate embeddings (stored in embeddings/).

3. Ensure Ollama is running with Mistral-7B loaded. You can start it with:
ollama serve &
ollama run mistral

4. Run app.py to launch the Streamlit UI and start using the chatbot:
streamlit run app.py